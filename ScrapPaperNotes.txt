Infra Automation
Open Source, Monetizes TF Cloud
provision and deploying infra via cfg
e.g.s create vpc, aws users and permissions, spinning up EC2s, installing docker
(in correct order)


good container orchestration support
good for replicating envs (e.g. dev, stage, prod)

Ansible is better for cfging images and apps onto a deployed infra.
Terraform is better for provisioning

The TF core engine parses cfg for desired state and compares to the current deployment state
It supports many cloud platforms (Iaas), Paas (e.g. kubernetes), and Saas (e.g. fastly CDN)


Declarative - cfgs describe desired state instead of actions to take (imperative)
TF executes the delta of steps to reach desired state

cmds
`terraform init` - initialize BE (state file storage, local by default)
downloads code for providers, into .terraform hidden directory
also downloads modules
creates a lock file, which contains dependency info

This backend should be remote, for security, collaboration, and automation,
this is possible with TF cloud (free for up to 5 users), s3 + dynamo, or other cloud service

Bootstraping State file: To do this, start with a local BE, provision the s3 in the config,
and then configure the remote backend into the cfg to be the provisioned config.

Multiple cfgs can specify the same backend


`terraform refresh` - gets current state
.. plan - previews the delta of necessary actions to reach desired state
.. apply - executes plan above.
instance attributes are known after apply.
you can see deploy in action on cloud UI.
.. destroy - removes entire deployment associated to this project

State file -
json format
reflects deployed infra : IP addrs, ARN (unique resource id), Data blocks (data outside of deployment, e.g. from a third party API)
> has sensitive data (passwords) <


Variables
Enables templating of configuration blocks and lines
Variables can be stored in a separate cfg file
string, nummber, boolean
list, set, mmap, object, tuple
custom conditions can be enforced on variables
e.g. Sensitive = true

Sensitive values are masked in TF CLI output

Input - like input params for a function
referenced as
Input - var.<name>

declared as
variable "instance_type" {
  description = "ec2 instance type"
  type = string
  default = "t2.micro"
}
setting precedence, low to high
cli prompt, when not supplied in cfg
default value in block
env variable, prefixed with tf_var_ (used in CI) (good for sensitive values)
terraform.tfvars in file systemm
*.auto.tfvars file
-var "my_var=foo" -var="another_var=bar"...
or -var-file <myvars.tfvars> option for plan or apply command (also good for sensitive values, can be passed in from AWSS secrets manager, giithub secret, or hashicorp vault)

local Variables - like local variables in a function, good for reuse
references as
local.<name>

declared as
locals {
  service_name = "my service"
  owner = "Terraform Dive"
}

output variables - like the return value of a function
gets values once provisioned (e.g. IP addr)
logged after apply cmd

declared as
output "instance_ip" {
  value = aws_instance.instance.public_ip
}

Expressions and Functions
template strings, math operators, conditions, loops, maps, and more
filesystem, date and time, encoding, type conversions and more

Meta-arguments
depends_on helps the engine maintain order of provisioning
count allows for creating multiple of the same resource and can be indexed (count.index)
for_each allows for iterables (e.g. cfg instance for list of subnet ids)
lifecycle (e.g. before destroy, ignore changes, prevent destroy)

provisioner
actions on local or remote machine


Best Practices

state and state file -
only update infra through TF commands, not the UI, not the state file.
create shared remote file for cfg (e.g. s3 with dynamo db for atomic locks, google cloud, TF cloud).
configure state file locking on storafge. depending on your provider, TF may lock the state file.
back up state file - enable versioning.
have 1 state file per env: dev, stage, prod.

Terraform Code / GitOps -
host tf code in git repo.
ensure the same review process as application code (i.e. PR reviews).
only CI/CD pipelines should make infra updates.




deploying 01-minimal

`brew install terraform`
google "install aws cli"
create iam group with permissions
create iam user and add it to the group

`aws configure`
click the username in iam > security credentials > create access key to get access key and secret
stored in ~/.aws/credentials on mac os

`terraform init`
`terraform plan`
`terraform apply`

deploying 02-webapp 
(back end)
# start with the backend cfg block commented out
`terraform init` # creates local be / state file
`terraform plan`
`terraform apply` # creates s3 + dynamo db for atomic locks
#after uncommenting backend cfg block
# note : replace the bucket name in the backend and resource blocks, where commented
`terraform init`

## Now this message shows:
##  "Pre-existing state was found while migrating the previous "local" backend to the
##  newly configured "s3" backend. No existing state was found in the newly
##  configured "s3" backend. Do you want to copy this state to the new "s3"
##  backend? Enter "yes" to copy and "no" to start with an empty state."


(web app)
# replace bucket names where commented
`terraform init` # inits backend stored in s3
`terraform plan`
# find the dns name (a record) for the LB in ec2 dashboard
# quickly enter this into the browser multiple times
# you will see both responses, meaning the lb is working